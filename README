Simple implementation of the Golomb Compressed Sets (GCS), a statistical
compressed data-structure. It is similar to Bloom filters, but it is far more
compact: given N elements, and P probability of a false positive, a Bloom
filter  requires at least N*log2(e)*log2(1/P) bits, where GCS requires closer
to N*log2(1/P). Given that log2(e) = 1.44..., it means that GCS are about
44% smaller than an equivalent Bloom filter.

The cons is of course speed: GCS is fully compressed so a query is an order of
magnituted slower than Bloom filters. On the other hand, it is not required to
decompress it fully in RAM, so it can be streamed. Thus, they make sense in an
environment where queries are performed at interactive rate and RAM is scarce
compared to the dataset.

The provided implementations are in Python and C++. They are fully equivalent,
but the C++ implementation caches the GCS in memory, while the Python implementation
streams it from disk. Examples of data sets (English and Italian dictionaries)
are provided to play with them. See test.sh.

See these references for more details:
http://www.imperialviolet.org/2011/04/29/filters.html
http://algo2.iti.uni-karlsruhe.de/singler/publications/cacheefficientbloomfilters-wea2007.pdf
